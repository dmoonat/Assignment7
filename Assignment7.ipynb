{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PONJIIyRHuS",
        "colab_type": "text"
      },
      "source": [
        "## Problem statement -\n",
        "\n",
        "**Generate \"fake English\" text from an RNN**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPZjvVZsV_p6",
        "colab_type": "text"
      },
      "source": [
        "### Task\n",
        "\n",
        "Given a character, or a sequence of characters, what is the most probable next character?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk8Pt2NWRFWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmzrckPNSlef",
        "colab_type": "text"
      },
      "source": [
        "#### Read data\n",
        "\n",
        "Dataset : Shakespeare's work, \n",
        "It is in text format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVSUrbhzS71g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = open('shakespeare_input.txt', 'rb').read().decode(encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRkx3ZxnTFU1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c0c3cbe-7b1d-4b93-c085-582bca3d4dc2"
      },
      "source": [
        "#we can find the length of the text using len function\n",
        "len(text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4573338"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAdL5ucTTQ5_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f15c7a7-e809-4dc4-ae4e-fe33fb050d04"
      },
      "source": [
        "text[:100]  #first 100 characters"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7-c0D4zTZRP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55146d43-69e2-46b3-ccd5-734a8d80c719"
      },
      "source": [
        "#we can find the vocabulary size by counting the unique characters in text\n",
        "vocab=sorted(set(text))\n",
        "len(vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6meuO9cdUEwf",
        "colab_type": "text"
      },
      "source": [
        "### Process data\n",
        "As we can feed text directly to our model so need to map our text data to some vector, so that we can have integer representation of each character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvL9ap_iT4u1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv_YpPXhUyT_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4c950e1b-1c95-4c90-f96a-cd010c009f45"
      },
      "source": [
        "print(repr(text[:15]))\n",
        "print(' ---------------')\n",
        "print(text_as_int[:15])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen:\\n'\n",
            " ---------------\n",
            "[18 49 58 59 60  1 15 49 60 49 66 45 54 10  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9wzZ8VWWhv1",
        "colab_type": "text"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a683bmU-W_L2",
        "colab_type": "text"
      },
      "source": [
        "Now we need to divide our text into a sequences, Each input sequence will contain seq_length characters from the text.\n",
        "For each input sequence, the corresponding targets contain the same length of text, except shifted one character to the right.\n",
        "\n",
        "So break the text into chunks of seq_length+1. For example, say seq_length is 4 and our text is \"Hello\". The input sequence would be \"Hell\", and the target sequence \"ello\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9ZIKJNyU93b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "1f9b15fd-733e-4000-8540-9857f11da762"
      },
      "source": [
        "# The tf.data.Dataset.from_tensor_slices function is used to convert the text vector into a stream of character indices.\n",
        "\n",
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//seq_length\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(i.numpy(),'-',idx2char[i.numpy()])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18 - F\n",
            "49 - i\n",
            "58 - r\n",
            "59 - s\n",
            "60 - t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwZJtZlKXe-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "1cd38017-4891-44d1-8d5a-aabcbd348c0b"
      },
      "source": [
        "# now we will convert this individual characters into sequences using batch method \n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(item)\n",
        "  print('-'*20)\n",
        "  print(repr(''.join(idx2char[item.numpy()])))\n",
        "  print('-'*20)\n",
        "  break"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[18 49 58 59 60  1 15 49 60 49 66 45 54 10  0 14 45 46 55 58 45  1 63 45\n",
            "  1 56 58 55 43 45 45 44  1 41 54 65  1 46 61 58 60 48 45 58  6  1 48 45\n",
            " 41 58  1 53 45  1 59 56 45 41 51  8  0  0 13 52 52 10  0 31 56 45 41 51\n",
            "  6  1 59 56 45 41 51  8  0  0 18 49 58 59 60  1 15 49 60 49 66 45 54 10\n",
            "  0 37 55 61  1], shape=(101,), dtype=int64)\n",
            "--------------------\n",
            "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3_JVz8AYjpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# as we want our input and target as : The input sequence would be \"Hell\", and the target sequence \"ello\"\n",
        "# we can use map function to apply a simple function to each batch\n",
        "\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IFOciXBZTda",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "36c603e1-c691-4bc4-84f4-7be3b020ce0c"
      },
      "source": [
        "for input_x, target_x in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_x.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_x.numpy()])))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9s06dqBaZd2",
        "colab_type": "text"
      },
      "source": [
        "Each index of these vectors are processed as one time step. For the input at time step 0, the model receives the index for \"F\" and trys to predict the index for \"i\" as the next character. At the next timestep, it does the same thing but the RNN considers the previous step context in addition to the current input character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqAzz5k5Z0Gu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "4043341d-bab5-4ab0-c891-26220a1f5765"
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_x[:5], target_x[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 18 ('F')\n",
            "  expected output: 49 ('i')\n",
            "Step    1\n",
            "  input: 49 ('i')\n",
            "  expected output: 58 ('r')\n",
            "Step    2\n",
            "  input: 58 ('r')\n",
            "  expected output: 59 ('s')\n",
            "Step    3\n",
            "  input: 59 ('s')\n",
            "  expected output: 60 ('t')\n",
            "Step    4\n",
            "  input: 60 ('t')\n",
            "  expected output: 1 (' ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyihiM_Va4Po",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ca4c937-bdf8-4e02-d9ca-6648d5b3887b"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Sclkodxb7M",
        "colab_type": "text"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC2sACSqyH6S",
        "colab_type": "text"
      },
      "source": [
        "I have used `tf.keras.Sequential` to define the model. \n",
        "\n",
        "We can add as many layers  as  we need in our  Sequential model\n",
        "\n",
        "* `tf.keras.layers.Embedding`: The input layer. A trainable lookup table that will map the numbers of each character to a vector with `embedding_dim` dimensions;\n",
        "\n",
        "* `tf.keras.layers.GRU`: A type of RNN with size `units=rnn_units` \n",
        "\n",
        "* `tf.keras.layers.LSTM`: A type of RNN with memory units of size `units=rnn_units`\n",
        "\n",
        "* `tf.keras.layers.Dense`: The output layer, with `vocab_size` outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2apqvVDHxGVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOUV8IzGzI_R",
        "colab_type": "text"
      },
      "source": [
        "Thus can try different layers together,\n",
        "\n",
        "#### Model 1\n",
        "- Embedding -> Lstm -> Dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK-iybvXyG8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model1(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0REX4Xx4zmUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = build_model1(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GerYgo7uz4HG",
        "colab_type": "text"
      },
      "source": [
        "For each character the model looks up the embedding, runs the LSTM one timestep with the embedding as input, and applies the dense layer to generate logits predicting the log-liklihood of the next character:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt56-x7hzuIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69569991-80d9-4c86-c5e2-393bdb779af3"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model1(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 67) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_sYE_B10HpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "64fe848a-c2c6-4b2e-bbc0-0fdf40a1ccf5"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           17152     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 67)            68675     \n",
            "=================================================================\n",
            "Total params: 5,332,803\n",
            "Trainable params: 5,332,803\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2xkh7ix0Xsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkFJMm6812Se",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e08ce90d-6d63-4e02-d398-c85130ee5203"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([62, 33, 36, 17,  9, 26, 28, 54, 63, 53, 57, 13, 24, 45, 27, 29, 44,\n",
              "       55, 54, 49, 50, 52, 28, 27, 23, 62, 39, 13, 12, 10, 18, 36, 49, 62,\n",
              "       12, 26, 41, 22, 33, 48, 13, 42,  3,  4,  2, 50, 42, 34, 13, 46, 27,\n",
              "       28, 50, 59, 53, 59, 63, 52, 28, 42, 65, 48,  4, 40, 62, 66, 17, 66,\n",
              "        9, 30, 25, 21, 31,  0, 23, 12, 65, 56, 40, 37, 28, 39, 43, 26, 32,\n",
              "       24, 44, 49, 46, 12, 47, 64, 56, 13, 58,  3, 55, 27, 19, 56])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIODhjUw14oj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "f11704ea-1dc7-470f-8cf6-056569af1377"
      },
      "source": [
        "# we will decode this sampled_indices into characters\n",
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " \"e stab him as he sleeps?\\n\\nFirst Murderer:\\nNo; then he will say 'twas done cowardly, when he wakes.\\n\\n\"\n",
            "\n",
            "Next Char Predictions: \n",
            " 'vUXE3NPnwmqALeOQdonijlPOKv[A?:FXiv?NaJUhAb$&!jbVAfOPjsmswlPbyh&]vzEz3RMIS\\nK?yp]YP[cNTLdif?gxpAr$oOGp'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLEeZP8S2u9D",
        "colab_type": "text"
      },
      "source": [
        "Now we will train our model1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro5IqwVQ3BoN",
        "colab_type": "text"
      },
      "source": [
        "We have to add optimizer and loss function to our model1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE6B-v9THzu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "648j2LnU2Bja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "947e3152-91d8-41e3-b724-9c70974c26f5"
      },
      "source": [
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 67)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.2048573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owqXhbSB3eZq",
        "colab_type": "text"
      },
      "source": [
        "Configure the training procedure using the tf.keras.Model.compile method. We'll use tf.keras.optimizers.Adam with default arguments and the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xREluCcO3e4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqou8STw3uhL",
        "colab_type": "text"
      },
      "source": [
        "We need to also save our model at checkpoints \n",
        "\n",
        "for this we will used a tf.keras.callbacks.ModelCheckpoint to ensure that checkpoints are saved during training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WUlwOzE3n8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = 'training_checkpoints_lstm_dense'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n",
        "\n",
        "tensorflow_checkpoint=tf.keras.callbacks.TensorBoard(log_dir='logs',write_graph=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojdJhELy4Nn9",
        "colab_type": "text"
      },
      "source": [
        "Now we will run our model1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrISlLSK4HbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XEozgKu4SlD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "b7b5b9c6-1136-4f7a-bc69-472f670b984e"
      },
      "source": [
        "history = model1.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "707/707 [==============================] - 57s 80ms/step - loss: 1.9736\n",
            "Epoch 2/10\n",
            "707/707 [==============================] - 55s 78ms/step - loss: 1.4473\n",
            "Epoch 3/10\n",
            "707/707 [==============================] - 55s 78ms/step - loss: 1.3435\n",
            "Epoch 4/10\n",
            "707/707 [==============================] - 55s 78ms/step - loss: 1.2898\n",
            "Epoch 5/10\n",
            "707/707 [==============================] - 55s 78ms/step - loss: 1.2509\n",
            "Epoch 6/10\n",
            "707/707 [==============================] - 55s 78ms/step - loss: 1.2179\n",
            "Epoch 7/10\n",
            "707/707 [==============================] - 55s 78ms/step - loss: 1.1879\n",
            "Epoch 8/10\n",
            "707/707 [==============================] - 55s 78ms/step - loss: 1.1608\n",
            "Epoch 9/10\n",
            "707/707 [==============================] - 55s 78ms/step - loss: 1.1378\n",
            "Epoch 10/10\n",
            "707/707 [==============================] - 55s 78ms/step - loss: 1.1207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW-EO8BU4fwC",
        "colab_type": "text"
      },
      "source": [
        "#### Now we will use our model1 for generating text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnWnZB9J6Nmg",
        "colab_type": "text"
      },
      "source": [
        "#### Restore\n",
        "\n",
        "\n",
        "\n",
        "Because of the way the RNN state is passed from timestep to timestep, the model only accepts a fixed batch size once built.\n",
        "\n",
        "To run the model with a different batch_size, we need to rebuild the model and restore the weights from the checkpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcETUGuA4XmX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6191005d-16d7-45b5-b50d-dd3f68fce098"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'training_checkpoints/ckpt_10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7kfJtcU4tqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model1(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu3Dqaaz4x0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "d12b28f1-cb95-4285-a202-ad11d17bdc0c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            17152     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (1, None, 1024)           5246976   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 67)             68675     \n",
            "=================================================================\n",
            "Total params: 5,332,803\n",
            "Trainable params: 5,332,803\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FWEFCuZ5cTr",
        "colab_type": "text"
      },
      "source": [
        "### The prediction loop\n",
        "\n",
        "The following code block generates the text:\n",
        "\n",
        "* It Starts by choosing a start string, initializing the RNN state and setting the number of characters to generate.\n",
        "\n",
        "* Get the prediction distribution of the next character using the start string and the RNN state.\n",
        "\n",
        "* Then, use a categorical distribution to calculate the index of the predicted character. Use this predicted character as our next input to the model.\n",
        "\n",
        "* The RNN state returned by the model is fed back into the model so that it now has more context, instead than only one word. After predicting the next word, the modified RNN states are again fed back into the model, which is how it learns as it gets more context from the previously predicted words.\n",
        "\n",
        "\n",
        "To generate text the model's output is fed back to the input\n",
        "\n",
        "Looking at the generated text, you'll see the model knows when to capitalize, make paragraphs and imitates a Shakespeare-like writing vocabulary. With the small number of training epochs, it has not yet learned to form coherent sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YFMXqUo51uW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 1000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  \n",
        "  tempera=[0.1,0.5,1.0,1.5,2]\n",
        "  \n",
        "  for temp in tempera:\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "        \n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        # remove the batch dimension\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # using a categorical distribution to predict the word returned by the model\n",
        "        predictions = predictions / temp\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "        # We pass the predicted word as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "    \n",
        "    ## saving the generated text to txt file\n",
        "    f = open(\"generatedtext_\"+str(temp)+\".txt\", \"a\")\n",
        "    f.writelines(text_generated)\n",
        "    f.close()\n",
        "    ##\n",
        "    \n",
        "    print('--'*30)\n",
        "    print('With temperature:',temp)\n",
        "    print('--'*30)\n",
        "    print(start_string + ''.join(text_generated))\n",
        "  #return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMJ7XtsrWqMo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b1758ed7-5b48-41e5-a64a-2064a217e72a"
      },
      "source": [
        "#lstm\n",
        "generate_text(model2load, start_string=u\"ESCALUS: \")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------\n",
            "With temperature: 0.1\n",
            "------------------------------------------------------------\n",
            "ESCALUS: I will desire thee again.\n",
            "\n",
            "ARVIRAGUS:\n",
            "You are the course of my dear lordship.\n",
            "\n",
            "LAUNCELOT:\n",
            "I will confess the mean time to the parties: I will find\n",
            "The court of England.\n",
            "\n",
            "LAUNCELOT:\n",
            "I will confess the money that I have not seen the mother of my love.\n",
            "\n",
            "POSTHUMUS LEONATUS:\n",
            "And I will speak a word of the moon.\n",
            "\n",
            "Second Lord:\n",
            "I thank you, good my lord.\n",
            "\n",
            "CLOTEN:\n",
            "The count hath been a solemn beard to stand at the devil.\n",
            "\n",
            "SIR TOBY BELCH:\n",
            "O, pardon me, my lord.\n",
            "\n",
            "PRINCESS:\n",
            "What is the matter? what should I stay the devil in the world?\n",
            "\n",
            "PISANIO:\n",
            "And I will follow thee a word of man that speaks of me\n",
            "And the contrary of a soldier here a good deed.\n",
            "\n",
            "CLIFFORD:\n",
            "And I will speak a word of my dear lord.\n",
            "\n",
            "LAUNCELOT:\n",
            "I will desire thee to the ground, and the contrary care\n",
            "I must be sounded in the world: I have not seen\n",
            "The secrets of my father's love.\n",
            "\n",
            "SUFFOLK:\n",
            "A thousand pound a course of mine; and I will follow thee again.\n",
            "\n",
            "ARVIRAGUS:\n",
            "Your servants are as a prince and a passion of the case.\n",
            "\n",
            "ANTIPHOLUS \n",
            "------------------------------------------------------------\n",
            "With temperature: 0.5\n",
            "------------------------------------------------------------\n",
            "ESCALUS: France shall be the hearts of man,\n",
            "Wherein they should be dearly for the caper,\n",
            "Which is at mighty soul, they have a catch in my body with the\n",
            "crown of Arthur's death.\n",
            "\n",
            "SIR ANDREW:\n",
            "Peace! a good words are not her blood;\n",
            "For he is fled, and but a soldier as her self-same hands\n",
            "Against the beards of Lord Timon, drop by thee\n",
            "And see thou the grave for thee; thou art not said\n",
            "The strong been press'd by one of them shall then well enough.\n",
            "\n",
            "ANTIPHOLUS OF EPHESUS:\n",
            "I thank you, good Master Slender, and thou bear'st of you.\n",
            "\n",
            "BELARIUS:\n",
            "I had my father's leave,--\n",
            "\n",
            "MISTRESS PAGE:\n",
            "A commodity of my lips.\n",
            "\n",
            "MONTANO:\n",
            "Marry, my lord, what care I now?\n",
            "\n",
            "VIOLA:\n",
            "Alas, sir, I would you will know what you went to speak my part;\n",
            "It is too hung to see him so: I have no spirit to be charged\n",
            "Upon the sun; and therefore show me more\n",
            "That I might stay that soldiers can cast away.\n",
            "\n",
            "Painter:\n",
            "I will come to you,\n",
            "When I will swear by means that and the course\n",
            "of all advantage, call'd upon the world\n",
            "To the warrant that\n",
            "------------------------------------------------------------\n",
            "With temperature: 1.0\n",
            "------------------------------------------------------------\n",
            "ESCALUS: he blood, I would have laid so long,\n",
            "They, sir; I hear but I.\n",
            "How fares de Saint AETES:\n",
            "That ists of my intent and doth happen'd:\n",
            "The well-bred smells the sea, by him his lips: he's confederate.\n",
            "\n",
            "SIR ANDREW:\n",
            "Shall I know thy father gidding this?\n",
            "\n",
            "HUBERT:\n",
            "Believe you and I thank you, give to make his brow.\n",
            "\n",
            "GLOUCESTER:\n",
            "My vigour'd blessed sir!\n",
            "What pockets set another\n",
            "old men? by the rather, like your enteries; too much for that eye\n",
            "The head doth prevent myself:\n",
            "From Sticlain count his vows lost fatal suit by clamour their orse of one, and this I borrow myself.\n",
            "\n",
            "MARIA:\n",
            "My devised dear friend! now, kings! let tell me\n",
            "What still is't upon 't?\n",
            "\n",
            "First Lord:\n",
            "What fight? now join we that hate,\n",
            "Still deeits?\n",
            "We cross it, like a dead that keep thou drown from.\n",
            "\n",
            "PANDARUS:\n",
            "From the sleepe sun. God save you, gently, gentle!\n",
            "Coming from Duncan are imperations of a tawny of it;\n",
            "And heard an enemy to chace,\n",
            "And they were glanted enough, and thereby laid almost sweep\n",
            "His resumping: but mark thee that \n",
            "------------------------------------------------------------\n",
            "With temperature: 1.5\n",
            "------------------------------------------------------------\n",
            "ESCALUS: Inivarch.\n",
            "\n",
            "QUEEN ELINOYK:\n",
            "Assuredly it, I jest: if you please\n",
            "To parndress youngludge;\n",
            "Syreart, de pantime! let it die. I'll get set Titanial\n",
            "em:n la!--walld, lasckldiending.--whe art begries,\n",
            "But viltion is\n",
            "alike: cold melamint--hais\n",
            "To fall, let them desirefa':\n",
            "Wargia, cordlichare a shaFFIIG:\n",
            "Allies; hid in fair, digst grow;\n",
            "Whereo Wavour's\n",
            "displease, I\n",
            "so my facelion?\n",
            "\n",
            "LAUNCELOT:\n",
            "I turn votre! \n",
            "ANNEPGLEF:\n",
            "Mounto sovere glum it; why I swear my nomme\n",
            "Murder the purse su carch at charge: allove lionsion.\n",
            "It could I stay with 'Amw'd their friend,\n",
            "To muster--Falstaspie or sworn and keep it s-foodwearate wine drawe.\n",
            "\n",
            "QUEEN:\n",
            "No; 'termstal; yoken, lest dug wal thus:\n",
            "Sway. tworned bankeep grows upon my alteration to\n",
            "the gluck, which proved s who\n",
            "canquesty so slaybert'er'd. Ha?\n",
            "\n",
            "Page, you'rd\n",
            "for he witaw; bul\n",
            "Wit--oaths for fowling?\n",
            "\n",
            "MISTREYNAPLESS:\n",
            "Mexh nay, or else Pind!\n",
            "\n",
            "Clown:\n",
            "I dreamber'dn I; the Ottempt bred, onose eap,\n",
            "Divisions, wonder, damn'd: urge his\n",
            "Arcasion? Bat's pudding!\n",
            "\n",
            "LUCE:\n",
            "------------------------------------------------------------\n",
            "With temperature: 2\n",
            "------------------------------------------------------------\n",
            "ESCALUS: \n",
            "l'tnge,\n",
            "LishiJOWne'ld SURIUS:\n",
            "Sylp to\n",
            "lun withay!--adriol ta. sot-e-en.\n",
            "\n",
            "LEWISSI:\n",
            "And that'smet, Mengaproen. Quijuiaur chasber\n",
            "TRINCUGE away? GlobtibleOtaturn!\n",
            "-voials, O Weuth!dworts; Thou make!\n",
            "ifG RENAUS:\n",
            "Inexpoings\n",
            "you! i' fain?\n",
            "folqueen'd qu' GoUIRY:\n",
            "Marry, Turca!\n",
            "Behopty,hises, aroped n'\n",
            "Papuke,.'\n",
            "l pale;\n",
            "carequious, take as day: Oberon!\n",
            "ay? occaviont, be, let goow defaly to be gl'd.\n",
            "Fonii,. But wilt, foos Why; between simp'INSRUIt 'twitaketmongiral ish-Humpory? May my coase\n",
            "Wear; stanz'd!\n",
            "\n",
            "CADE:\n",
            "Who cozes he;\n",
            "Of chamberago so?\n",
            "\n",
            "VAURSI,\n",
            "By\n",
            "God flot.\n",
            "Yoo, Canws Bin\n",
            "two kits' fury till our hualmanny thyself buy it,\n",
            "Light our passyalls' viwagordist; bot, visareab, wert catrme;\n",
            "My; witt's--enced:\n",
            "Plithed;\n",
            "But baur Senatus.'\n",
            "Has, Francr:\n",
            "three orditiod 's all, dreast,\n",
            "at Cepea,amature to'll,, charmcic: thw\n",
            "Why, like I y;\n",
            "By thee, mow, had'Us; l keep'st thealsiL:\n",
            "Butful us--but fooly-thoughr!'To tainted him!\n",
            "But It fellths,\n",
            "Attumat in; and, I'll one.\n",
            "Mina nose. Ne poison fond eab us. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZGHgeTrNwmP",
        "colab_type": "text"
      },
      "source": [
        "#### Using GRU Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wct_JwpD72Ls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model2(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwZ-3VHvL0eU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = build_model2(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjh_P1bKMyma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "49db49bf-f77c-4127-f8bc-32324998aca3"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (64, None, 256)           17152     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (64, None, 67)            68675     \n",
            "=================================================================\n",
            "Total params: 4,024,131\n",
            "Trainable params: 4,024,131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp1lqoP-M9ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9vPWk5TNSsg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "99634e94-514e-491b-f402-921a5ce80673"
      },
      "source": [
        "history2 = model2.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "707/707 [==============================] - 47s 66ms/step - loss: 2.0087\n",
            "Epoch 2/10\n",
            "707/707 [==============================] - 46s 65ms/step - loss: 1.4632\n",
            "Epoch 3/10\n",
            "707/707 [==============================] - 46s 65ms/step - loss: 1.3603\n",
            "Epoch 4/10\n",
            "707/707 [==============================] - 46s 65ms/step - loss: 1.3083\n",
            "Epoch 5/10\n",
            "707/707 [==============================] - 46s 65ms/step - loss: 1.2708\n",
            "Epoch 6/10\n",
            "707/707 [==============================] - 46s 65ms/step - loss: 1.2395\n",
            "Epoch 7/10\n",
            "707/707 [==============================] - 46s 65ms/step - loss: 1.2119\n",
            "Epoch 8/10\n",
            "707/707 [==============================] - 46s 65ms/step - loss: 1.1888\n",
            "Epoch 9/10\n",
            "707/707 [==============================] - 46s 65ms/step - loss: 1.1719\n",
            "Epoch 10/10\n",
            "707/707 [==============================] - 46s 65ms/step - loss: 1.1615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXB1ZAJlP_-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2load = build_model2(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model2load.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model2load.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOiowoxTQLpz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "968a0ee1-22db-438a-b4a7-b9c9ce487b1b"
      },
      "source": [
        "model2load.summary()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (1, None, 256)            17152     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (1, None, 67)             68675     \n",
            "=================================================================\n",
            "Total params: 4,024,131\n",
            "Trainable params: 4,024,131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1evQjfc9PlvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4fb28054-4023-42b1-8fb5-ad328fed6acc"
      },
      "source": [
        "#GRU\n",
        "generate_text(model2load, start_string=u\"ESCALUS: \")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------\n",
            "With temperature: 0.1\n",
            "------------------------------------------------------------\n",
            "ESCALUS: I will desire thee with the\n",
            "strength of a strange and a man as he were as good as the sea,\n",
            "Which should be so able to be but the devil in the world,\n",
            "That hath a part of a fair conference that it doth begin\n",
            "to give them me against the beards of love\n",
            "And call the streets of England shall be sounded.\n",
            "\n",
            "SIR ANDREW:\n",
            "An you do not know my dear friends to the state of mine;\n",
            "And I will stay the course of my dear lordship.\n",
            "\n",
            "LAUNCELOT:\n",
            "I will consider thee in the world:\n",
            "I am a soldier to a soldier that shall be the world.\n",
            "\n",
            "PISANIO:\n",
            "I am not so well that the matter of my lord,\n",
            "The cardinal, in the world is sound,\n",
            "And then he shall be so able to be bless'd with their shores.\n",
            "The cardinal, if thou didst not see the deed.\n",
            "\n",
            "SUFFOLK:\n",
            "A plague upon him, and I will not say\n",
            "'The devil and my father's leaves and charge of fear.\n",
            "\n",
            "LONGAVILLE:\n",
            "You may that be a man to see your worship and call it for the course\n",
            "of the sea and a part of a fair contempt.\n",
            "\n",
            "SIR ANDREW:\n",
            "An you do not, sir.\n",
            "\n",
            "FALSTAFF:\n",
            "I will desire\n",
            "------------------------------------------------------------\n",
            "With temperature: 0.5\n",
            "------------------------------------------------------------\n",
            "ESCALUS: xt the first of the corruption\n",
            "And in their battles strength of marriage for thy life.\n",
            "\n",
            "CLARENCE:\n",
            "I am not so far from your course that I would be so, but not a warrant to the morning with thee.\n",
            "\n",
            "SIR ANDREW:\n",
            "A rough to the infected world\n",
            "And then he may the world in south but the scared days,\n",
            "To give the hearts of death to such a one shall be as many as the adversary\n",
            "As thou art thinking. Is the sun and hearts of flesh?\n",
            "\n",
            "Second Lord:\n",
            "Here's a good grandam.\n",
            "\n",
            "KING JOHN:\n",
            "We will abuse my land be put to do it.\n",
            "\n",
            "SIR ANDREW:\n",
            "Ay, and I will confess the more cannon and die in arms.\n",
            "\n",
            "CADE:\n",
            "Well said, I say.\n",
            "\n",
            "First Murderer:\n",
            "Why, then, be not gone to the deed. I say again\n",
            "I know not where they were as here as good as a wing, for my part,\n",
            "I'll read the charge of heaven.\n",
            "\n",
            "EMILIA:\n",
            "O my good lord, I cannot go from me.\n",
            "\n",
            "ANTONIO:\n",
            "Well, no more.\n",
            "\n",
            "FALSTAFF:\n",
            "I am glad your worship from her that sleeps do so.\n",
            "\n",
            "Third Lord:\n",
            "I'll be as vanity.\n",
            "\n",
            "ARVIRAGUS:\n",
            "On the devil it is the whilst an honest man\n",
            "That shal\n",
            "------------------------------------------------------------\n",
            "With temperature: 1.0\n",
            "------------------------------------------------------------\n",
            "ESCALUS: ady:\n",
            "Do, fell, majesty, which before,\n",
            "I must give no jetter than your highness hid\n",
            "and of my love; but I would not desire your best again.\n",
            "\n",
            "First Senator:\n",
            "Welcome, would thou art merry by, being but a plebeia\n",
            "to modern. I am a kind of sorrow; if my lady I speak to utter what\n",
            "halter damn'd, be others of taint: I would my breast not I before\n",
            "my fortune can do not, stand close down what acquaintance\n",
            "Which timut accepts more than mirth withal.\n",
            "\n",
            "PORTIA:\n",
            "You made to murder me for thee. if thou might\n",
            "Makes such business of my grandam's breath,\n",
            "Hanging better, a pout.\n",
            "I will deny it that hath style for our dread.\n",
            "\n",
            "PRINCE HENRY:\n",
            "Thou unworthiest sweet thelifried,\n",
            "With old purved high tench twings so swear\n",
            "To fancy enterprofant.\n",
            "Who was soleit up well understood.\n",
            "\n",
            "BRUTUS:\n",
            "And charge you, sir: but my gentleman\n",
            "and wisdok words away myself.\n",
            "\n",
            "DICK:\n",
            "\n",
            "CADE:\n",
            "It is:\n",
            "Now as for who had heard it,\n",
            "That hunting them from them. His trick upon you\n",
            "Against, and know\n",
            "Your dates are as your eyes. To his huge da\n",
            "------------------------------------------------------------\n",
            "With temperature: 1.5\n",
            "------------------------------------------------------------\n",
            "ESCALUS: rh; robe theen;\n",
            "Where thou?\n",
            "He is admitth?\n",
            "\n",
            "MARIA:\n",
            "No, by so brave, yet I'll marry him; for who\n",
            "TIGAS:\n",
            "Upon my direch-report sburnur'd: it would;\n",
            "so, age with five thousandfus goln the licious venturous\n",
            "ughation\n",
            "As beggary bur\n",
            "Alchorman\n",
            "Ross and swifter dows you both, sUng prodigable:\n",
            "Soon give thee much allo's.\n",
            "\n",
            "ADRIANAy:\n",
            "D horse! as lobberl is too vow! I'll ogadate?\n",
            "Let me one Laer:\n",
            "If contais'd in sope violet-ape\n",
            "That I love sought to'd il with him: O, oy.\n",
            "Goodmanvoy,' says.\n",
            "\n",
            "CAIUShe more: truly; a whit.\n",
            "\n",
            "SHALLOW:\n",
            "Gives tuma,\n",
            "Andmen! Good mavicablowand.\n",
            "Jajy,t thou\n",
            "Cold witchfal; colvement ull,\n",
            "Hear keeper's breast.\n",
            "Anded i' the sanlCUNIUS;\n",
            "Let ERHESOBut O, hear me. Why offend, I'll are\n",
            "quick-divines vicin a-galled dutient than plist.\n",
            "O'er brave secreason! will you then, madam!\n",
            "\n",
            "It Foksmise, touch CLoathmerale\n",
            "To chteue yours i' themselves.\n",
            "\n",
            "Ay.\n",
            "Now ornofould ne'ee our a\n",
            "loy\n",
            "Dungerous Harry's foul'd an hour DINCH:\n",
            "Give me alove;\n",
            "Mistresst, else'h like 'eait's. cleen, nay, so rs,\n",
            "abr\n",
            "------------------------------------------------------------\n",
            "With temperature: 2\n",
            "------------------------------------------------------------\n",
            "ESCALUS: yautio;\n",
            "Avod, putithlated, la! yet\n",
            "Pood, my mother; touch'nobly juxtite.\n",
            "Buy urkentu,\n",
            "Is sucE, madam Gref;\n",
            "Give'll-taciten or most valiant ready;\n",
            "It whose rss\n",
            "meeh'sokeiswit and diday: ha, Goz\n",
            "divinquennje:\n",
            "Forgivr! Master Syourk.\n",
            "It urpirco\n",
            "deliver't.'\n",
            "WARRty, Smiling fanes:\n",
            "carry's days and wombl have folfoy\n",
            "Qud Nyma?' Thies:\n",
            "Wousds wrife? wey.\n",
            "say I, thau,'dlab.\n",
            "\n",
            "IDAPHakis naurtes rag of dange\n",
            "often: wike DrSRISTELWA. Copus'At;\n",
            "or,\n",
            "if Monbriy's opp'ce?-Lly';\n",
            "r, dau eye-a lar hitrewmory; his qubjow, en\n",
            "Fishowoives 'chonsive peanch, couwru,\n",
            "But illscinisletip squecven oncy\n",
            "musied-windenju';\n",
            "Sinjunes,--why, taking Her IIRO:\n",
            "O place ith crvel zragged.\n",
            "\n",
            "VIULL: I'll rums budst chat's\n",
            "\n",
            "SINAUS:\n",
            "But u'Of RG!\n",
            "\n",
            "FLUELLET:\n",
            "\n",
            "ULYBOPSID:\n",
            "His am custion.\n",
            "no fee; maquo, Bucbud\n",
            "I-Mirvyist's blessbll:\n",
            "Tr nthw Shake? w Warwea,\n",
            "Arm four cause\n",
            "Cernooly Bugs. Hercursof! Can's\n",
            "byright's. Is the ir\n",
            "glde her issuherigo:\n",
            "But tark, F never, I kiso's\n",
            "by othervasimp upon. Tu-sevendidiqual On!\n",
            "LQUNEf twevin my Dor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FIZz_k-WyrH",
        "colab_type": "text"
      },
      "source": [
        "#### Model3 \n",
        "**embedding -> lstm -> dense(1024) -> dense(67)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HyVlQEDTqTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model3(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(1024),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRK8-UirWEhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = build_model3(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1kKAoq_WEbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "359b2137-914a-44ca-fd7f-874040b9f9b7"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (64, None, 256)           17152     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (64, None, 1024)          1049600   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (64, None, 67)            68675     \n",
            "=================================================================\n",
            "Total params: 6,382,403\n",
            "Trainable params: 6,382,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "estXfVsRWU3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "e602e939-61df-4efe-ce6c-b30de398266e"
      },
      "source": [
        "model3.compile(optimizer='adam', loss=loss)\n",
        "history3 = model3.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback],save_scores=True)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "707/707 [==============================] - 62s 88ms/step - loss: 2.0864\n",
            "Epoch 2/10\n",
            "707/707 [==============================] - 62s 88ms/step - loss: 1.5087\n",
            "Epoch 3/10\n",
            "707/707 [==============================] - 62s 88ms/step - loss: 1.3789\n",
            "Epoch 4/10\n",
            "707/707 [==============================] - 62s 88ms/step - loss: 1.3144\n",
            "Epoch 5/10\n",
            "707/707 [==============================] - 62s 88ms/step - loss: 1.2693\n",
            "Epoch 6/10\n",
            "707/707 [==============================] - 62s 88ms/step - loss: 1.2309\n",
            "Epoch 7/10\n",
            "707/707 [==============================] - 62s 88ms/step - loss: 1.1947\n",
            "Epoch 8/10\n",
            "707/707 [==============================] - 62s 88ms/step - loss: 1.1590\n",
            "Epoch 9/10\n",
            "707/707 [==============================] - 63s 88ms/step - loss: 1.1247\n",
            "Epoch 10/10\n",
            "707/707 [==============================] - 62s 88ms/step - loss: 1.0934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLlyMzuyWi3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3load = build_model3(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model3load.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model3load.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXlxOMDtWouJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "fdf9e584-7403-4cc8-cfe4-b058ea488247"
      },
      "source": [
        "model3load.summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (1, None, 256)            17152     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (1, None, 1024)           5246976   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (1, None, 1024)           1049600   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (1, None, 67)             68675     \n",
            "=================================================================\n",
            "Total params: 6,382,403\n",
            "Trainable params: 6,382,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPEzk_Vndd45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ca10fab-8f69-4f00-c443-b8c71c3512f9"
      },
      "source": [
        "generate_text(model3load, start_string=u\"ESCALUS: \")"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------\n",
            "With temperature: 0.1\n",
            "------------------------------------------------------------\n",
            "ESCALUS: have you come to do?\n",
            "\n",
            "ANTONIO:\n",
            "O, the devil that I will set down the streets\n",
            "Of this distilled day and the devil's\n",
            "damnations, as the sun should be as the sounds\n",
            "are out of a commonweal.\n",
            "\n",
            "SIR ANDREW:\n",
            "Ay, an't please your lordship.\n",
            "\n",
            "POSTHUMUS LEONATUS:\n",
            "You are too shameful to my lord.\n",
            "\n",
            "CLOTEN:\n",
            "The sweet war from the prince,\n",
            "And there the sun should be as little as the world,\n",
            "That he shall stand at supper-time to do,\n",
            "That they have left their bloody stones by thee,\n",
            "That he shall see the gentleman of good and last,\n",
            "And then she cannot bloody strokes of nature,\n",
            "That were the gentleman of nation, whom\n",
            "I would not be so constant with the beard,\n",
            "And then she shall be suffer'd. Here is the story.\n",
            "\n",
            "POSTHUMUS LEONATUS:\n",
            "The spirit of me not still: if you will find it out.\n",
            "\n",
            "LUCIANA:\n",
            "What is the matter?\n",
            "\n",
            "POINS:\n",
            "Marry, sir, will you be contented: there is no\n",
            "better to be short that hath so much delicate them\n",
            "to the moon. I have seen the lightning for a fool.\n",
            "\n",
            "POINS:\n",
            "I would I were a lord of the cour\n",
            "------------------------------------------------------------\n",
            "With temperature: 0.5\n",
            "------------------------------------------------------------\n",
            "ESCALUS: ich fair accoutrement.\n",
            "If you should forget that she could not speak,\n",
            "But in the spots of slaughter and the bottom\n",
            "It should be so soon as a careful seem\n",
            "To be so far intered not thy food,\n",
            "And for my soul and harbour is a sin,\n",
            "Have you a soul shall serve my life, my lord,\n",
            "No more than fortune in my father's death.\n",
            "\n",
            "KING JOHN:\n",
            "Why dost thou stay thy lands?\n",
            "\n",
            "IMOGEN:\n",
            "You shouldst leave this behavior for my life,\n",
            "I will content thee for thy love:\n",
            "And I think the last married with my soul,\n",
            "That he is proved then, and thy mother's son\n",
            "Stays in the field.\n",
            "\n",
            "POSTHUMUS LEONATUS:\n",
            "New still, my lord, in the shores of this manner;\n",
            "For, in the nature of a sea from fear\n",
            "The silver bloody of the land and late\n",
            "Whereon the blood of parliament slaves,\n",
            "And set thee for a pair of manners,\n",
            "And drown him here in act. How now, my heart!\n",
            "\n",
            "MARIA:\n",
            "I do not think the word is cold, my lord.\n",
            "\n",
            "ANTIPHOLUS OF EPHESUS:\n",
            "My lord, we will demand these ere I could be well\n",
            "companied. I should have a letter that I should\n",
            "eat\n",
            "------------------------------------------------------------\n",
            "With temperature: 1.0\n",
            "------------------------------------------------------------\n",
            "ESCALUS: he more change\n",
            "of her gifts, and do on persous time that every bears\n",
            "that should stabbeard, fled, might give us good stars.\n",
            "\n",
            "John Macoffer's legs\n",
            "That can more than he was Sir John Master Slender, let her\n",
            "use him, and be justly entered.\n",
            "\n",
            "DICK:\n",
            "\n",
            "PUCKIN:\n",
            "O the head,\n",
            "What old you labow? where are you their words?\n",
            "But that mysteries,\n",
            "What in what confirment lies not without thought,\n",
            "Prick'd its fit words, no.\n",
            "\n",
            "OLIVIA:\n",
            "Warking 'gainst Loceus! I will besee:\n",
            "Poor servito f pe?\n",
            "Wer't rut this city?\n",
            "\n",
            "PISANIO:\n",
            "What, finger of a soul,\n",
            "Lest rabblessed as many footed night,\n",
            "Hence men, tie master, warwing, manners,\n",
            "looks into the cardinals\n",
            "To give my thoughts together, feeble froe.\n",
            "The duke he has so credit in my heart;\n",
            "And he that living, is't not known to thy\n",
            "I led down Jack, and I fear not diwnack\n",
            "A substitute prohich; in my petting-skin,\n",
            "That will make lenve to death them all about;\n",
            "Great Aaris, does concean hamable yet\n",
            "That Portia and the high and envy hours.\n",
            "Let them go, happy, give our goddin\n",
            "------------------------------------------------------------\n",
            "With temperature: 1.5\n",
            "------------------------------------------------------------\n",
            "ESCALUS: ;\n",
            "Thou likest I see't! thine neivel d. Murderer.\n",
            "\n",
            "TIMON:\n",
            "I am of r\n",
            "sch-houts. I had last ribborr\n",
            "to: I were brla\n",
            "r Irelicate of even;\n",
            "open'ts ago. If thou worthy spirits, jealous.\n",
            "\n",
            "PISTOL:\n",
            "To appoint rechangival:\n",
            "You were the yoked \n",
            "Not O, I seem to welcome agbemph Dernio,\n",
            "Who with a ladder gibes a feeder-thighlder father's?\n",
            "once.\n",
            "\n",
            "TITUS:\n",
            "\n",
            "SATUMDLE TIE:\n",
            "My womb, with sad contuments: and I\n",
            "did: either it please your grace, you my r-coat.\n",
            "\n",
            "TRANIO:\n",
            "Make overchangeast\n",
            "Shook,--of I kniwe-joured knightly.\n",
            "\n",
            "WESTMOLUS:\n",
            "Come, both: So Cleoice home, Had tor geis feiture,\n",
            "Surfeit.'Zom so?,--envy you,--return,\n",
            "dishonour,\n",
            "yp!\n",
            "You!\n",
            "Your fairer own gold have wunti'll goleff\n",
            "abroad, I cannot report by any may strre vandy; dity\n",
            "La's less.\n",
            "\n",
            "DOLL SEOPH:\n",
            "Oh, ?\n",
            "Knight with inward imperis od\n",
            "ve know day or day; and that's the contunago d?--\n",
            "Thorive le, Haer. O.\n",
            "hispons or sever't enigs,\n",
            "Having suffer'd his cocio-men.\n",
            "\n",
            "AARON:\n",
            "O sir, I would\n",
            "Content ourlommen. I\n",
            "will, dyz\n",
            "will now appear time; mad, say we sho\n",
            "------------------------------------------------------------\n",
            "With temperature: 2\n",
            "------------------------------------------------------------\n",
            "ESCALUS: ns? O villany;\n",
            "Whereupon hadst rsillntes\n",
            "and at bleming.\n",
            "\n",
            "HAMLET:\n",
            "Suirep'r;  is liked Fife's refuummebegetwer: but when if you baca\n",
            "deliver,\n",
            "we bringe theso moch\n",
            "pojkindives? But which.\n",
            "Meld.\n",
            "\n",
            "he carried Hart crars.\n",
            "Peace is befome,\n",
            "I'mnlethbysour handzdodkesmommach.'\n",
            "Sit jars is;'xenapcoing?\n",
            "\n",
            "Wirdsr thou: a\n",
            "Greciliail ca's-Jusethio! woman.\n",
            "how disciply over her? tows; loyou see?\n",
            "rop'bly?'--'pahvil o'clyhle, give't?\n",
            "\n",
            "Hoe but, miraching felowlinking. SIC:\n",
            "Whereje breek y!\n",
            "voucdericasiend\n",
            "$utINA:\n",
            "Gre comfortrill, k.\n",
            "No; if I toed\n",
            "cousins-away, Llujenies. Aver th Gre traps cithik\n",
            "Tha, gw'htles, vilgispe!--Bucobs have knone:\n",
            "Oors,\n",
            "I'morn ke m, you are. Bo, unce guilt,\n",
            "dish!\n",
            "Pompetuing defforbery!--\n",
            "As\n",
            "Jod,-wafeave awfr-merry eSDUO:\n",
            "\n",
            "PISCO que i' snake.' 'goum trade.' or  m sweetlnamive you from tied law,--yonary ria!\n",
            "a gerke-insawch, wide!\n",
            "Deunbul, blocded, blur-varfelIN:\n",
            "Yet yonou tribune. Norfe!\n",
            "h! ins? No chance: my GOUGNOTES:\n",
            "Hapk:\n",
            "Mean thAle\n",
            "RIDHLETND:\n",
            "Solvidet you, madmen, lays; itho\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mESCUc2Sb33I",
        "colab_type": "text"
      },
      "source": [
        "#### Model4\n",
        "**embedding  ->  gru  ->  gru -> dense(1024) -> dense(67)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1vocXQJZGmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model4(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(1024),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaoWKsEncJwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model4 = build_model4(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9WInt1KcMjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "7ec9f779-c157-423c-8189-3baf13ec4cef"
      },
      "source": [
        "model4.summary()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (64, None, 256)           17152     \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (64, None, 1024)          6297600   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (64, None, 1024)          1049600   \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (64, None, 67)            68675     \n",
            "=================================================================\n",
            "Total params: 11,371,331\n",
            "Trainable params: 11,371,331\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sSiIpthcS52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "18b8a40b-4096-44cd-97f3-b7729efc6672"
      },
      "source": [
        "model4.compile(optimizer='adam', loss=loss)\n",
        "history4 = model4.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "707/707 [==============================] - 110s 155ms/step - loss: 2.0327\n",
            "Epoch 2/10\n",
            "707/707 [==============================] - 108s 152ms/step - loss: 1.4685\n",
            "Epoch 3/10\n",
            "707/707 [==============================] - 108s 152ms/step - loss: 1.3637\n",
            "Epoch 4/10\n",
            "707/707 [==============================] - 108s 153ms/step - loss: 1.3076\n",
            "Epoch 5/10\n",
            "707/707 [==============================] - 108s 153ms/step - loss: 1.2633\n",
            "Epoch 6/10\n",
            "707/707 [==============================] - 108s 153ms/step - loss: 1.2223\n",
            "Epoch 7/10\n",
            "707/707 [==============================] - 108s 153ms/step - loss: 1.1845\n",
            "Epoch 8/10\n",
            "707/707 [==============================] - 108s 153ms/step - loss: 1.1544\n",
            "Epoch 9/10\n",
            "707/707 [==============================] - 108s 153ms/step - loss: 1.1353\n",
            "Epoch 10/10\n",
            "707/707 [==============================] - 108s 153ms/step - loss: 1.1193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqY9PLd3c8vN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model4load = build_model4(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model4load.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model4load.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARczUFWZdAV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "eebc9a62-74ed-4fee-efce-be13a471b4be"
      },
      "source": [
        "model4load.summary()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (1, None, 256)            17152     \n",
            "_________________________________________________________________\n",
            "gru_6 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "gru_7 (GRU)                  (1, None, 1024)           6297600   \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (1, None, 1024)           1049600   \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (1, None, 67)             68675     \n",
            "=================================================================\n",
            "Total params: 11,371,331\n",
            "Trainable params: 11,371,331\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s3kf28ZdFkf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10e4d1b2-2e6c-48bd-c3f4-345ea1443bee"
      },
      "source": [
        "generate_text(model4load, start_string=u\"ESCALUS: \")"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------\n",
            "With temperature: 0.1\n",
            "------------------------------------------------------------\n",
            "ESCALUS: I will not find it to a base men.\n",
            "\n",
            "SIR ANDREW:\n",
            "Ay, ay: I will see you in the conscience of my father's charge.\n",
            "\n",
            "CLOTEN:\n",
            "Thou art a very fight for my father; and I will not find\n",
            "my father's wife with that be thy part.\n",
            "\n",
            "SIR ANDREW:\n",
            "Ay, and the best blood will stand still content the good gods.\n",
            "\n",
            "SIR TOBY BELCH:\n",
            "O, a peace! the devil that she did pluck a jot of man,\n",
            "And cast the words of sounds and fortunes\n",
            "You would not have the best appear with that\n",
            "Which his confirmation that my father was a gentleman.\n",
            "\n",
            "LUCIANA:\n",
            "What is the matter with the sin to the court?\n",
            "\n",
            "SIR ANDREW:\n",
            "Ay, my good lord.\n",
            "\n",
            "KING JOHN:\n",
            "A good soul for him.\n",
            "\n",
            "ARVIRAGUS:\n",
            "You are the first that ever I will have them all the world\n",
            "That I might stay for me to foreign correction.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "What is thy name?\n",
            "\n",
            "MISTRESS QUICKLY:\n",
            "Why, my lord?\n",
            "\n",
            "ALCIBIADES:\n",
            "Ay, and the prince with sorrow we have seen the conscience\n",
            "of it. Sir John, I say, I will not fail not of your\n",
            "company. I tell you that I will not stay the first.\n",
            "\n",
            "ARVIRAGUS\n",
            "------------------------------------------------------------\n",
            "With temperature: 0.5\n",
            "------------------------------------------------------------\n",
            "ESCALUS: TARD:\n",
            "What, the candle mother of my love with him?\n",
            "\n",
            "Porter:\n",
            "You mad, beseech you, will you not be shored?\n",
            "\n",
            "WILLIAM PAGE:\n",
            "Not so with that?\n",
            "\n",
            "CASSIO:\n",
            "You must not speak. No more than we have still to say it is this his soul\n",
            "As doth the market-place and course of mine.\n",
            "\n",
            "LADY MACBETH:\n",
            "You would not be a fresh but welcome.\n",
            "\n",
            "PISANIO:\n",
            "Fie, fie!\n",
            "\n",
            "SIR TOBY BELCH:\n",
            "O, peace!\n",
            "\n",
            "SALARINO:\n",
            "I know not, madam: 'tis a good cardinal.\n",
            "\n",
            "CONSTANCE:\n",
            "What should I were a lady that I have a sharp thou?\n",
            "\n",
            "Lady:\n",
            "Ay, he does: he'll be with you, sir:\n",
            "Yet I will find it to a good mouthsant fire,\n",
            "To blame in that within the lion-pit like a conquest\n",
            "but the sweet of many thousand of mischiefs that are of these bloody fixed\n",
            "counterfeit to the base crowns: I will forgive you\n",
            "this world to buy a bondman, a pair of fear,\n",
            "And so am I not well with that apparent\n",
            "That he deserves to speak to him, and there\n",
            "my father carriage him to the market-place of conscience\n",
            "To say I am sorry that you are lock'd; the wine that may be stu\n",
            "------------------------------------------------------------\n",
            "With temperature: 1.0\n",
            "------------------------------------------------------------\n",
            "ESCALUS: pon all o'er manner shall I\n",
            "leave my brother fat.\n",
            "The garlen of mine honour,\n",
            "Enlarge yies and hazards so for't.\n",
            "Who called, thou?\n",
            "\n",
            "VIOLA:\n",
            "Why for a card al nond, no fault within this light of that,\n",
            "But for my many jealousu of breedings; who with some\n",
            "ale in dew o' the babbling man,\n",
            "Lminch for love, with the worst,\n",
            "As didear grows married that sufficenith Lucius\n",
            "Justice kindless for a better joy?\n",
            "\n",
            "Clown:\n",
            "Peace! let the fight than the groundious Bois is after\n",
            "my food, by this hand. Who knocks that question?\n",
            "\n",
            "Merciply:\n",
            "His golden pri, y-violence, and thou shalt hereithee come you\n",
            "Must his u sea money? ere you\n",
            "Creat us 'tis to Take's will, I pray you,\n",
            "all to Courtier on.\n",
            "\n",
            "PISTOL:\n",
            "Why then shall drive the very fear of him\n",
            "As I cannot;\n",
            "And that same stream, which is the bell, swears;\n",
            "And,--as knack, he should curse his\n",
            "plains: and you, my master gently steel,\n",
            "Have cut a capaioue thus blawness.\n",
            "\n",
            "CADE:\n",
            "by his course for a strabe, note my father;\n",
            "and for his conficed it is put forth\n",
            "May take my\n",
            "------------------------------------------------------------\n",
            "With temperature: 1.5\n",
            "------------------------------------------------------------\n",
            "ESCALUS: : I'll taste, 'What's may's cog aquous humour-raisbut dienight:\n",
            "'Tis virtue: thy never havion I ench'd;\n",
            "An wildnation, flacking ongless\n",
            "fellews, Somerseu, blows t,\n",
            "Coar's swiltetwixt fingery, aslasseth bs fuito.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Peacifling, ho! Mustur\n",
            "Cannot mouff this bloody cox? I will addebw\n",
            "The rich asleageness,.\n",
            "Come: there! Sleeves incense of l onocks out,\n",
            "To pick eaiticutuptunsitiate words ridicts.\n",
            "\n",
            "SALISBURY:\n",
            "A harveRNAUPHIAN:\n",
            "We are ye to Siltia;\n",
            "God will my earner hog it by the axecution\n",
            "Not stirze a good actor:\n",
            "A peace betrumpaddy;\n",
            "And good Aumiriujunurzed, Obads,\n",
            "Hath kept to\n",
            "chid Ja'enby? Would it speaks, vidarowhar, farello!:\n",
            "Jp qKUTH:\n",
            "We'rADANDULl.\n",
            "\n",
            "ANTONIUt.\n",
            "\n",
            "SMI botn me hofps: ne'er flty Richard.'\n",
            "us\n",
            "thy brack with thy imaginations:\n",
            "which is too naught the natural-way?RD IV:\n",
            "It well incest lethus\n",
            "Quince; wholes forth thou? Heler,\n",
            "Delivered thy, i' father's lip,'-Thus gennews I will cut, for it is myself.\n",
            "Beaststeeptity,ty.\n",
            "\n",
            "POTTOL:\n",
            "I give Latiendlance\n",
            "Smiled abagity,\n",
            "A\n",
            "------------------------------------------------------------\n",
            "With temperature: 2\n",
            "------------------------------------------------------------\n",
            "ESCALUS: TOUYO:\n",
            "Dorohe.\n",
            "Antimeo thy woxinian tys:\n",
            "thy mitila I cuilmont\n",
            "tme Walpot.\n",
            "\n",
            "WICL:'\n",
            "Thou specthap e\n",
            "right: forcil ! 'tis hils;\n",
            "Tume, to his hopes,\n",
            "Ind l beps,-Our anceggrel?\n",
            "inqY,\n",
            "And flinow, fla mu!,Uk:\n",
            "Do not feThis.\n",
            "Bring greatlious nft.\n",
            "\n",
            "PleapeRE:\n",
            "I heard us at anish?\n",
            "\n",
            "BIEPANM:\n",
            "AmeOM: OLM:\n",
            "Wilt to.\n",
            "\n",
            "MORTJUQUITINE:\n",
            "A pr,\n",
            "wute a you\n",
            "kill'st Opilius, I do,\n",
            "I law\n",
            "Witty lips.\n",
            "\n",
            "FURE? sTALBURY.\n",
            "Hie t. Those swickspossaies mub\n",
            "MMY:\n",
            "Dack,\n",
            "I'd adker h'tis;\n",
            "O lords phymbais ni$ed, yours i'ft.\n",
            "Misivers\n",
            "A act o'-woss' Vece and r buttrim me.\n",
            "\n",
            "KCAAV:\n",
            "You mobcip me tony,--\n",
            "TMVIO:\n",
            "Sive ll toys, kinng Lend tan'og:\n",
            "Madam, choave mine a hope' in,I' ipon\n",
            "cool? hoy' doth vucw a pilcked by none,--I fencd. Yter;\n",
            "Sprittomings.\n",
            "\n",
            "FLORIZEL:\n",
            "We armar of treachery behinds,\n",
            "Our arturprd 'desrimpth me. Althe,\n",
            "To bur I'ln by: wy:\n",
            "Sffesdway: O yield Macfibfiupowstwhy,\n",
            "StmbeauilEG,\n",
            "vusiding ; by  aceagy tydkED\n",
            "Trier,, of two? t? forbnkfue conceiving--MARZUGFGUV:\n",
            "Muta nupriuajek mu 'Y, pnwI fai.\n",
            "Centolenkh kings;.,\n",
            "Wi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSPI4HTMGdJ2",
        "colab_type": "text"
      },
      "source": [
        "**model 5**\n",
        "\n",
        "**embedding -> lstm -> lstm -> dense(512) -> dense(67)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGybcXRq8-tS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model4(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(512),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwOL7gGmGTuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model5 = build_model4(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SRv3H9rGrI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "46d0bdf9-13c8-466e-8ec4-f73b978e9ccf"
      },
      "source": [
        "model5.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           17152     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (64, None, 1024)          8392704   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 512)           524800    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (64, None, 67)            34371     \n",
            "=================================================================\n",
            "Total params: 14,216,003\n",
            "Trainable params: 14,216,003\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r835gnGLGtat",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "outputId": "0a1e38ca-336f-48ae-8c9d-98104aa71ac6"
      },
      "source": [
        "# with 20 epochs\n",
        "model5.compile(optimizer='rmsprop', loss=loss)\n",
        "history5 = model5.fit(dataset, epochs=20, callbacks=[checkpoint_callback,tensorflow_checkpoint])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "  1/707 [..............................] - ETA: 1:17:47 - loss: 4.2063"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0701 06:02:42.504052 140026019379072 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.256256). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "707/707 [==============================] - 150s 212ms/step - loss: 2.3367\n",
            "Epoch 2/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 1.4351\n",
            "Epoch 3/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 1.3266\n",
            "Epoch 4/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 1.2659\n",
            "Epoch 5/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 1.2148\n",
            "Epoch 6/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 1.1657\n",
            "Epoch 7/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 1.1160\n",
            "Epoch 8/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 1.0658\n",
            "Epoch 9/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 1.0160\n",
            "Epoch 10/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 0.9682\n",
            "Epoch 11/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 0.9236\n",
            "Epoch 12/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 0.8823\n",
            "Epoch 13/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 0.8455\n",
            "Epoch 14/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 0.8130\n",
            "Epoch 15/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 0.7845\n",
            "Epoch 16/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 0.7601\n",
            "Epoch 17/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 0.7389\n",
            "Epoch 18/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 0.7201\n",
            "Epoch 19/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 0.7037\n",
            "Epoch 20/20\n",
            "707/707 [==============================] - 145s 205ms/step - loss: 0.6893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EgQ2wEyT7Cv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93df4a9e-c384-4688-856b-66fbc73663b4"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'training_checkpoints_lstm_dense/ckpt_20'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GNDIl9hTjX0",
        "colab_type": "text"
      },
      "source": [
        "Load the model weights and again build model for batch size 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kvZgidSIExY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model5load = build_model4(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model5load.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model5load.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j4B3Rc7LJJP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "6f46d810-a185-4c3e-84ab-e1909ea8473a"
      },
      "source": [
        "model5load.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            17152     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (1, None, 1024)           5246976   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (1, None, 1024)           8392704   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (1, None, 512)            524800    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (1, None, 67)             34371     \n",
            "=================================================================\n",
            "Total params: 14,216,003\n",
            "Trainable params: 14,216,003\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrA2r0_LUEta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a738dd3a-c66c-41b2-a4ce-8d3ff50d8882"
      },
      "source": [
        "generate_text(model5load, start_string=u\"ESCALUS: \")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------\n",
            "With temperature: 0.1\n",
            "------------------------------------------------------------\n",
            "ESCALUS: be not afraid, good master; he swears; and to\n",
            "be so able to bear it, sigh;\n",
            "I mean, the man is honest, with a supposed\n",
            "babbed: then, that would have made me sick,\n",
            "That in a dream,\n",
            "And that my son is left and honour, all in bastards,\n",
            "To think men are the things to call upon you?\n",
            "\n",
            "Second Lord:\n",
            "Lord Timon's mad.\n",
            "\n",
            "Second Clove passing well.\n",
            "\n",
            "CONSTANCE:\n",
            "What say you to set on their drinking?\n",
            "\n",
            "Second Lord:\n",
            "I will not think it.\n",
            "\n",
            "CONSTANCE:\n",
            "What say you to set on their drinking?\n",
            "\n",
            "Second Lord:\n",
            "I will not think a fat man to my husband he is dead,\n",
            "And that supposed by the times of the wars\n",
            "Should nothing pray as proud, our pleasure,\n",
            "My manleeprows made in the contrary.\n",
            "\n",
            "KING HENRY VI:\n",
            "What say these young ones?\n",
            "\n",
            "SIR TOBY BELCH:\n",
            "What say you to set on their charity,\n",
            "And to the crown import?\n",
            "\n",
            "Second Lord:\n",
            "\n",
            "CLOTEN:\n",
            "I have heard the courtier; and then we will none of the\n",
            "marriage whereof, my lord, the Duke of Exeter hath\n",
            "accounts me to my love: but I will drag\n",
            "For them to mend them all, and will not s\n",
            "------------------------------------------------------------\n",
            "With temperature: 0.5\n",
            "------------------------------------------------------------\n",
            "ESCALUS:  the trumpet of the prince of\n",
            "valour into Hecamp,\n",
            "Being an officer of an hundred marks.\n",
            "\n",
            "Second Lord:\n",
            "Sir, at the last, the ladies of the way of day,\n",
            "That hath been borne the throat, and the most value,\n",
            "Love's trumpet throws in assime this forest-better,\n",
            "That in a second conflictory, domines:\n",
            "The world, I tell you, and to haste again,\n",
            "To see the waters on their backs,\n",
            "And steps into the crown; and let them kiss your honour,\n",
            "Whom you will neigh to part with her.\n",
            "\n",
            "TIMON:\n",
            "I have heard, and, by my troth, I kissed to\n",
            "your pleasure.\n",
            "\n",
            "CONSTANCE:\n",
            "O, upon my knee,\n",
            "Where is my love, the knight is not high to tell him\n",
            "That now hath told me too?\n",
            "\n",
            "IMOGEN:\n",
            "I am sorry for't, my lord.\n",
            "\n",
            "CARDINAL WOLSEY:\n",
            "My sovereign lady, hear me speak.\n",
            "\n",
            "POSTHUMUS LEONATUS:\n",
            "I am glad to see your griefs; and whatsoever come home to bed, with two\n",
            "ways; the two months at first: he truly found\n",
            "To any sword out.\n",
            "\n",
            "Second Gentleman:\n",
            "A royal train, my lord, a witch.\n",
            "\n",
            "Second Gentleman:\n",
            "As I am a gentleman, they were comfortable\n",
            "------------------------------------------------------------\n",
            "With temperature: 1.0\n",
            "------------------------------------------------------------\n",
            "ESCALUS: \n",
            "With love and such addition,\n",
            "As husbands have;\n",
            "By heaven, I fear, my lord, this prince.\n",
            "\n",
            "Cydan, and too much\n",
            "fellows and bond;\n",
            "If say to me, my liege, I do not think so\n",
            "This presence of these slidices, gowards,\n",
            "Put my to tell you any crown int by a ths to\n",
            "dance with your backs. What a thing you have no more,\n",
            "How I shall please the counterpoise of his neck,\n",
            "A power will be upon you both, tell her;\n",
            "No, heaven not to immediately deserve a weet.\n",
            "\n",
            "PHILO:\n",
            "And look to the ground they set in the very jest above deaf:\n",
            "Both young at not come:\n",
            "Life grief and gentle and your necks,\n",
            "Make me to damn him to the tenor? The king,\n",
            "even in the merrow, Lord AEneas,\n",
            "To trust him sounds, and profits little in tonight,\n",
            "To fulsch we alive, night at his defence;\n",
            "Some sudden, nice-wasted with such waste,\n",
            "My hand deliver'd to my everlasting lords\n",
            "More hated, kind tas broken with the time\n",
            "Untils mough as smooth that bears, high clap-trenched, parts I'll crepe; who hath severam dream of honour,\n",
            "With fear and grow\n",
            "------------------------------------------------------------\n",
            "With temperature: 1.5\n",
            "------------------------------------------------------------\n",
            "ESCALUS: ith death.\n",
            "I quarre in't; even so\n",
            "To keep our tender baby strong peering\n",
            "We put it to this triKlor's dam:\n",
            "And then, it looks but fool'low, or throws quick,\n",
            "Over thy chase; for, Moreliy,\n",
            "I thank thee, Belloan: te-moe of\n",
            "night! I went now our gapers of Troilus'\n",
            "Livine or indignation, shrieked\n",
            "halters, hoped about BaGOR:\n",
            "Ay, that's the way so ruel'd,\n",
            "But taking thy name new fires rash treasure.\n",
            "\n",
            "IAGO:\n",
            "Long live shame!\n",
            "\n",
            "EARL OF WORCESTER:\n",
            "But if the crew paramooper a voluntary,\n",
            "honest, tripple of, aside, thin wandering apir,\n",
            "Like an't eir; and follows,\n",
            "Peand it out-faced, and oftentimes done\n",
            "Came in your brothers, and to Clement's In:\n",
            "Am not Apemantus, my lord, that fail'st,\n",
            "the glory of occasion sleeping,\n",
            "I'll liquity in all: what is thy meat?\n",
            "But here, come;\n",
            "Remember\n",
            "Must Warwick could prove up the Sterne troops.\n",
            "\n",
            "GERNOBor of the Hotspur's scholar.\n",
            "O, turn his natural company,--\n",
            "\n",
            "All:\n",
            "The cardinal raked; Gloucester, drawn\n",
            "To thisy-beat boot-all he day:\n",
            "We do remember what say's man!\n",
            "\n",
            "OBE\n",
            "------------------------------------------------------------\n",
            "With temperature: 2\n",
            "------------------------------------------------------------\n",
            "ESCALUS: REBANT:\n",
            "Modera,\n",
            "My Lord of Amogon, presently.\n",
            "far with me: foir i' the madge I, O!\n",
            "Hat, ! Fie, judgle, look! at otcem, nut,\n",
            "k.\n",
            "\n",
            "ALCIBIADES:\n",
            "Surel, cut. By my volia;--\n",
            "My tongue. My games and my gray learn, rebuke me;\n",
            "'Tis not his wont to cour, who canst\n",
            "Call French; I am hulf-most foil'd, or de\n",
            "You so to hell. Now, my gentle news,\n",
            "Wheece moe the due and brother!--noy hid,\n",
            "m\n",
            "In such apbit of us, that his ignorant il 'd\n",
            "bleeding;\n",
            "Must I behold, what;\n",
            "Camilia,\n",
            "Go justly; indeed, of gumina ipright.\n",
            "\n",
            "Second Gentleman:\n",
            "Shows pure r'doubtle Egyptionerron, slain:--tell\n",
            "me, inter.\n",
            "\n",
            "WARWICK:\n",
            "A lady-cause, to Cimbiacr's sword;\n",
            "At suffies Mortimer, ?\n",
            "What know'st thof? Is't not thou fr brave, answer\n",
            "Nothing of mine;\n",
            "Whol, 'tis that tetler,' I can eat loss than is King.\n",
            "\n",
            "GUILDENSTERN:\n",
            "The Dauphinhe fleefe.\n",
            "\n",
            "ULYSSES:\n",
            "Still, woounr,\n",
            "You will piecel you, an't please you, sleep?\n",
            "Where's yount's growing .\n",
            "\n",
            "LEWIS:\n",
            "Is thy neighbour?\n",
            "\n",
            "Brothers! Caesar's:\n",
            "As willingly as trust's Tubastian,\n",
            "Far\n",
            "able together\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTEoYCfuV2mN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTlzs9QdTp6I",
        "colab_type": "text"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "- Got a mixture of meaningful and unmeaningful sequences(outputs).\n",
        "- With low temperature value we get better results\n",
        "- Single layer of LSTM perform comparable as two layers of GRU thus lstm is much better choice for text generation\n",
        "- With different architecture we can generate much meaningful text\n",
        "- With increase in epochs we can also increase our model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OGLZg8jXn18",
        "colab_type": "text"
      },
      "source": [
        "#### Download the logs from colab for tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rwBGgTWXni7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "b8a15025-8f11-446b-afbe-325b01352d6e"
      },
      "source": [
        "!zip -r /content/logs_.zip /content/logs"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/logs/ (stored 0%)\n",
            "  adding: content/logs/train/ (stored 0%)\n",
            "  adding: content/logs/train/events.out.tfevents.1561960955.8bb5a3af85c3.124.1397.v2 (deflated 82%)\n",
            "  adding: content/logs/train/events.out.tfevents.1561960962.8bb5a3af85c3.profile-empty (deflated 5%)\n",
            "  adding: content/logs/train/plugins/ (stored 0%)\n",
            "  adding: content/logs/train/plugins/profile/ (stored 0%)\n",
            "  adding: content/logs/train/plugins/profile/2019-07-01_06-02-42/ (stored 0%)\n",
            "  adding: content/logs/train/plugins/profile/2019-07-01_06-02-42/local.trace (deflated 93%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZc4f50mYr_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}